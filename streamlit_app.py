# streamlit_app.py
# ---------------------------------------------------------
# MovieLens 1M + AutoInt ì¶”ì²œ ë°ëª¨ (Streamlit)
# - Folder: data/ml-1m | artifacts | model
# ---------------------------------------------------------

from pathlib import Path
import pickle
import numpy as np
import pandas as pd
import streamlit as st

# ========== PATH ì„¤ì • ==========
DATA_DIR = Path("data/ml-1m")
ART_DIR  = Path("artifacts")
MODEL_DIR = Path("model")

USERS_FILE   = DATA_DIR / "users.dat"
MOVIES_FILE  = DATA_DIR / "movies.dat"
RATINGS_FILE = DATA_DIR / "ratings.dat"
FIELD_DIMS_PATH = ART_DIR / "field_dims.npy"
ENCODER_PATH    = ART_DIR / "label_encoders.pkl"
WEIGHTS_PATH    = MODEL_DIR / "autoInt_model.weights.h5"

# ========== Streamlit ê¸°ë³¸ ì„¤ì • ==========
st.set_page_config(page_title="ğŸ¬ MovieLens AutoInt", layout="wide")
st.title("ğŸ¬ MovieLens 1M AutoInt ì¶”ì²œ ì‹œìŠ¤í…œ")

# ========== TensorFlow Import ë° ì´ˆê¸°í™” ==========
tf_loaded = False
try:
    import tensorflow as tf
    from tensorflow import keras
    from tensorflow.keras import layers
    tf_loaded = True
except Exception as e:
    st.error("âŒ TensorFlow import ì‹¤íŒ¨ â€” requirements.txt ë° íŒŒì´ì¬ ë²„ì „ì„ í™•ì¸í•˜ì„¸ìš”.")
    st.exception(e)
    # st.stop() # TensorFlow ì˜¤ë¥˜ ì‹œì—ë„ ë‹¤ë¥¸ ê¸°ëŠ¥ì„ í…ŒìŠ¤íŠ¸í•  ìˆ˜ ìˆë„ë¡ ê°•ì œ ì¢…ë£Œ ì œê±°

# ========== ë°ì´í„° ë¡œë“œ ==========
@st.cache_data(show_spinner=False)
def load_tables():
    """MovieLens ë°ì´í„°ì…‹ ë¡œë“œ"""
    users = pd.read_csv(
        USERS_FILE, sep="::", engine="python",
        names=["user_id","gender","age","occupation","zip"],
        encoding="latin-1"
    )
    movies = pd.read_csv(
        MOVIES_FILE, sep="::", engine="python",
        names=["movie_id","title","genres"],
        encoding="latin-1"
    )
    ratings = pd.read_csv(
        RATINGS_FILE, sep="::", engine="python",
        names=["user_id","movie_id","rating","timestamp"],
        encoding="latin-1"
    )
    ratings["label"] = (ratings["rating"] >= 4).astype(int)
    ratings["ts"] = pd.to_datetime(ratings["timestamp"], unit="s")
    movies["main_genre"] = movies["genres"].str.split("|").str[0]
    return users, movies, ratings


# ========== ì•„í‹°íŒ©íŠ¸ ë° ëª¨ë¸ ë¡œë“œ ==========
@st.cache_resource(show_spinner=False)
def load_artifacts_and_model():
    """artifacts ë° ëª¨ë¸ ë¡œë“œ (í˜•ì‹ ìë™ ê°ì§€)"""

    # 1) field_dims
    try:
        field_dims = np.load(FIELD_DIMS_PATH, allow_pickle=True)
        field_dims = np.asarray(field_dims).astype(np.int64).ravel()
    except Exception as e:
        st.error("âŒ field_dims.npy ë¡œë“œ ì‹¤íŒ¨")
        st.exception(e)
        raise

    # 2) label_encoders.pkl
    try:
        with open(ENCODER_PATH, "rb") as f:
            enc_raw = pickle.load(f)
    except pickle.UnpicklingError as e:
        # pickle.UnpicklingError ë°œìƒ ì‹œ, ë²„ì „ ë¶ˆì¼ì¹˜ ê°€ëŠ¥ì„±ì„ ëª…í™•íˆ ì•ˆë‚´
        st.error("âŒ label_encoders.pkl ë¡œë“œ ì‹¤íŒ¨: Pickle ì˜¤ë¥˜ ë°œìƒ (ë¼ì´ë¸ŒëŸ¬ë¦¬ ë²„ì „ ë¶ˆì¼ì¹˜ ê°€ëŠ¥ì„± ë†’ìŒ)")
        st.warning("ê²½ê³ : ì´ ì˜¤ë¥˜ëŠ” ì¼ë°˜ì ìœ¼ë¡œ ëª¨ë¸ì„ ì €ì¥í•  ë•Œ ì‚¬ìš©í–ˆë˜ Python/scikit-learn/Pandas ë²„ì „ê³¼ í˜„ì¬ í™˜ê²½ì˜ ë²„ì „ì´ ì¼ì¹˜í•˜ì§€ ì•Šì„ ë•Œ ë°œìƒí•©ë‹ˆë‹¤. `requirements.txt` íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
        st.exception(e)
        raise
    except Exception as e:
        st.error("âŒ label_encoders.pkl ë¡œë“œ ì‹¤íŒ¨")
        st.exception(e)
        raise

    default_cat_cols = ["user_id","movie_id","gender","age","occupation","zip","main_genre"]

    # --- êµ¬ì¡° ìë™ í•´ì„ ---
    if isinstance(enc_raw, dict) and "label_encoders" in enc_raw:
        label_encoders = enc_raw["label_encoders"]
        cat_cols = enc_raw.get("cat_cols", default_cat_cols)
    elif isinstance(enc_raw, dict):
        label_encoders = enc_raw
        cat_cols = default_cat_cols
        st.warning("label_encoders.pklì— cat_cols í‚¤ê°€ ì—†ì–´ ê¸°ë³¸ ìˆœì„œ ì‚¬ìš©")
    elif isinstance(enc_raw, (tuple, list)) and len(enc_raw) == 2:
        cat_cols = list(enc_raw[0]) if isinstance(enc_raw[0], (list, tuple)) else default_cat_cols
        label_encoders = enc_raw[1]
    else:
        # ìµœì¢… ValueError ë°œìƒ ì§€ì : ë²„ì „ ë¶ˆì¼ì¹˜ ì™¸ì— íŒŒì¼ êµ¬ì¡° ìì²´ê°€ ì˜ˆìƒê³¼ ë‹¤ë¥¼ ë•Œ
        st.error("âŒ label_encoders.pkl êµ¬ì¡° í•´ì„ ë¶ˆê°€")
        st.warning("ê²½ê³ : íŒŒì¼ ë‚´ë¶€ êµ¬ì¡°ê°€ ì½”ë“œê°€ ì˜ˆìƒí•˜ëŠ” ë”•ì…”ë„ˆë¦¬, íŠœí”Œ, ë¦¬ìŠ¤íŠ¸ í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤. ëª¨ë¸ ì €ì¥ ë¡œì§ì„ í™•ì¸í•˜ì„¸ìš”.")
        raise ValueError("label_encoders.pkl êµ¬ì¡°ë¥¼ í•´ì„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    # --- field_dims ë³´ì • ---
    if len(field_dims) != len(cat_cols):
        try:
            field_dims = np.array([len(label_encoders[c]) for c in cat_cols], dtype=np.int64)
            st.info("field_dims ê¸¸ì´ë¥¼ label_encoders ê¸°ë°˜ìœ¼ë¡œ ì¬ê³„ì‚°í–ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            st.error("field_dims ì¬ê³„ì‚° ì‹¤íŒ¨")
            st.exception(e)
            raise
    
    # --- ëª¨ë¸ êµ¬ì„± ---
    if not tf_loaded:
        st.error("TensorFlow ë¡œë“œ ì‹¤íŒ¨ë¡œ ëª¨ë¸ì„ êµ¬ì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return cat_cols, label_encoders, field_dims, None # ëª¨ë¸ ê°ì²´ ëŒ€ì‹  None ë°˜í™˜

    num_fields  = len(cat_cols)
    embed_dim   = 32
    num_heads   = 4
    attn_layers = 2
    dropout_rate= 0.2
    mlp_units   = [128, 64]

    inp = keras.Input(shape=(num_fields,), dtype="int32")
    embeds = []
    for i, dim in enumerate(field_dims):
        vi = layers.Lambda(lambda x, idx=i: tf.gather(x, indices=idx, axis=1))(inp)
        vi = layers.Reshape((1,))(vi)
        ei = layers.Embedding(input_dim=int(dim), output_dim=embed_dim)(vi)
        embeds.append(ei)
    E = layers.Concatenate(axis=1)(embeds)

    x = E
    for _ in range(attn_layers):
        attn_out = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim, dropout=dropout_rate)(x, x)
        x = layers.Add()([x, attn_out])
        x = layers.LayerNormalization()(x)

    x = layers.GlobalAveragePooling1D()(x)
    for u in mlp_units:
        x = layers.Dense(u, activation="relu")(x)
        x = layers.Dropout(dropout_rate)(x)
    out = layers.Dense(1, activation="sigmoid")(x)

    model = keras.Model(inputs=inp, outputs=out)
    model.compile(optimizer="adam", loss="binary_crossentropy")

    _ = model.predict(np.zeros((1, num_fields), dtype=np.int32), verbose=0)
    try:
        model.load_weights(str(WEIGHTS_PATH))
    except Exception as e:
        st.error("âŒ ê°€ì¤‘ì¹˜ ë¡œë“œ ì‹¤íŒ¨ â€” model/autoInt_model.weights.h5 í™•ì¸ í•„ìš”")
        st.exception(e)
        raise

    return cat_cols, label_encoders, field_dims, model


# ========== ì¶”ì²œ ë¡œì§ ==========
def map_single(label_encoders, col, val):
    m = label_encoders[col]
    return m.get(str(val), 0)

def recommend_for_user(users, movies, ratings, cat_cols, label_encoders, model, user_id: int, topn: int = 10):
    # ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨ ì‹œ ì¶”ì²œ ë¡œì§ ì‹¤í–‰ ë°©ì§€
    if model is None:
        st.error("ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•„ ì¶”ì²œì„ ì§„í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return pd.DataFrame(columns=["movie_id","title","genres","score"])

    u = users[users["user_id"] == user_id]
    if len(u) == 0:
        g, a, o, z = "M", 25, 0, "00000"
    else:
        g, a, o, z = u.iloc[0][["gender","age","occupation","zip"]]

    seen = set(ratings.loc[ratings["user_id"]==user_id, "movie_id"].tolist())
    cand = movies[~movies["movie_id"].isin(seen)].copy()
    if cand.empty:
        return pd.DataFrame(columns=["movie_id","title","genres","score"])

    cand["main_genre"] = cand["genres"].str.split("|").str[0]

    mg_idx = cand["main_genre"].astype(str).map(label_encoders["main_genre"]).fillna(0).astype(int).values
    m_idx  = cand["movie_id"].astype(str).map(label_encoders["movie_id"]).fillna(0).astype(int).values

    g_idx = map_single(label_encoders, "gender", g)
    a_idx = map_single(label_encoders, "age", a)
    o_idx = map_single(label_encoders, "occupation", o)
    z_idx = map_single(label_encoders, "zip", z)
    u_idx = map_single(label_encoders, "user_id", user_id)

    n = len(cand)
    U = np.full((n,), u_idx, dtype=np.int32)
    M = m_idx # movie_id
    G = np.full((n,), g_idx, dtype=np.int32)
    A = np.full((n,), a_idx, dtype=np.int32)
    O = np.full((n,), o_idx, dtype=np.int32)
    Z = np.full((n,), z_idx, dtype=np.int32)
    MG = mg_idx # main_genre

    # ì£¼ì˜: Xë¥¼ cat_cols ìˆœì„œì— ë§ê²Œ ìŠ¤íƒí•´ì•¼ í•©ë‹ˆë‹¤.
    # default_cat_cols = ["user_id","movie_id","gender","age","occupation","zip","main_genre"]
    X = np.stack([U, M, G, A, O, Z, MG], axis=1)

    scores = model.predict(X, batch_size=65536, verbose=0).ravel()
    out = cand.assign(score=scores).sort_values("score", ascending=False).head(topn)
    return out[["movie_id","title","genres","score"]]


# ========== ì‹¤í–‰ ==========
try:
    users, movies, ratings = load_tables()
    cat_cols, label_encoders, field_dims, model = load_artifacts_and_model()

    if model is None:
        st.error("ì¶”ì²œ ì‹œìŠ¤í…œ í•µì‹¬ ëª¨ë“ˆ(TensorFlow/ëª¨ë¸) ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ìœ„ì˜ ì˜¤ë¥˜ ë©”ì‹œì§€ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        st.stop()
        
except Exception as e:
    st.error("ì´ˆê¸° ë°ì´í„° ë˜ëŠ” ëª¨ë¸ ë¡œë“œ ì¤‘ ì‹¬ê°í•œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì•±ì„ ë” ì´ìƒ ì‹¤í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    st.exception(e)
    st.stop()


uid = st.selectbox("ğŸ‘¤ User ID ì„ íƒ", sorted(users["user_id"].unique().tolist()))
topn = st.slider("ì¶”ì²œ ê°œìˆ˜", 5, 50, 10, 1)

st.markdown("#### ìµœê·¼ ì‹œì²­ ì´ë ¥")
hist = (
    ratings[ratings["user_id"]==uid]
    .sort_values("ts", ascending=False)
    .head(10)
    .merge(movies[["movie_id","title","genres"]], on="movie_id", how="left")
)
st.dataframe(hist[["movie_id","rating","ts","title","genres"]], use_container_width=True)

if st.button("ğŸ” ì¶”ì²œ ë³´ê¸°"):
    with st.spinner("ì¶”ì²œ ê³„ì‚° ì¤‘..."):
        recs = recommend_for_user(users, movies, ratings, cat_cols, label_encoders, model, int(uid), topn)
    st.markdown("#### ì¶”ì²œ ê²°ê³¼")
    st.dataframe(recs.reset_index(drop=True), use_container_width=True, height=400)
else:
    st.info("User IDì™€ ì¶”ì²œ ê°œìˆ˜ë¥¼ ì„¤ì •í•˜ê³  ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")