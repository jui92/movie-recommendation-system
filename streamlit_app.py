import os
from pathlib import Path
import pickle
import numpy as np
import pandas as pd
import streamlit as st

# -----------------------------
# 0) TensorFlow ê°€ë“œ
# -----------------------------
try:
    import tensorflow as tf
    from tensorflow import keras
    from tensorflow.keras import layers
except Exception as e:
    st.error(
        "TensorFlowë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\n"
        "requirements.txtì™€ runtime.txtë¥¼ í™•ì¸í•˜ì„¸ìš”.\n\n"
        f"[ì›ì¸] {e}"
    )
    st.stop()

st.set_page_config(page_title="MovieLens AutoInt Recommender", layout="wide")

# -----------------------------
# 1) ê²½ë¡œ/í•„ìˆ˜ íŒŒì¼ ì²´í¬
# -----------------------------
DATA_DIR = Path("data/ml-1m")
ART_DIR  = Path("artifacts")
MODEL_W  = Path("model/autoInt_model.weights.h5")  # â† ë°˜ë“œì‹œ .weights.h5

required_files = [
    DATA_DIR / "users.dat",
    DATA_DIR / "movies.dat",
    DATA_DIR / "ratings.dat",
    ART_DIR / "field_dims.npy",
    ART_DIR / "label_encoders.pkl",
    MODEL_W,
]
missing = [str(p) for p in required_files if not p.exists()]
if missing:
    st.error("í•„ìˆ˜ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ë ˆí¬ì§€í† ë¦¬ì— í¬í•¨í•´ ì£¼ì„¸ìš”:\n\n" + "\n".join(missing))
    st.stop()

# -----------------------------
# 2) ë°ì´í„° ë¡œë”© (ìºì‹œ)
# -----------------------------
@st.cache_data(show_spinner=False)
def load_small_tables():
    users = pd.read_csv(DATA_DIR / "users.dat", sep="::", engine="python",
                        names=["user_id","gender","age","occupation","zip"])
    movies = pd.read_csv(DATA_DIR / "movies.dat", sep="::", engine="python",
                         names=["movie_id","title","genres"])
    ratings = pd.read_csv(DATA_DIR / "ratings.dat", sep="::", engine="python",
                          names=["user_id","movie_id","rating","timestamp"])
    ratings["label"] = (ratings["rating"] >= 4).astype(int)
    ratings["ts"] = pd.to_datetime(ratings["timestamp"], unit="s")
    ratings["rating_year"]  = ratings["ts"].dt.year
    ratings["rating_month"] = ratings["ts"].dt.month
    movies["main_genre"] = movies["genres"].str.split("|").str[0]
    return users, movies, ratings

@st.cache_resource(show_spinner=False)
def load_artifacts_and_model():
    # ---- artifacts
    try:
        field_dims = np.load(ART_DIR / "field_dims.npy")
        with open(ART_DIR / "label_encoders.pkl", "rb") as f:
            enc_obj = pickle.load(f)
        cat_cols       = enc_obj["cat_cols"]
        label_encoders = enc_obj["label_encoders"]
    except Exception as e:
        st.error("ì•„í‹°íŒ©íŠ¸ ë¡œë“œ ì‹¤íŒ¨(field_dims / label_encoders). íŒŒì¼ì„ í™•ì¸í•´ ì£¼ì„¸ìš”.\n\n" + str(e))
        st.stop()

    # ---- AutoInt êµ¬ì¡° (í•™ìŠµê³¼ ë™ì¼í•´ì•¼ í•¨)
    num_fields  = len(cat_cols)
    embed_dim   = 32
    num_heads   = 4
    attn_layers = 2
    dropout_rate = 0.2
    mlp_units   = [128, 64]

    inp = keras.Input(shape=(num_fields,), dtype="int32")
    embeds = []
    for i, dim in enumerate(field_dims):
        vi = layers.Lambda(lambda x: tf.gather(x, indices=i, axis=1))(inp)  # (B,)
        vi = layers.Reshape((1,))(vi)
        ei = layers.Embedding(input_dim=int(dim), output_dim=embed_dim)(vi) # (B,1,E)
        embeds.append(ei)
    E = layers.Concatenate(axis=1)(embeds)  # (B,F,E)

    x = E
    for _ in range(attn_layers):
        attn_out = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim, dropout=dropout_rate)(x, x)
        x = layers.Add()([x, attn_out])
        x = layers.LayerNormalization()(x)

    x = layers.GlobalAveragePooling1D()(x)
    for u in mlp_units:
        x = layers.Dense(u, activation="relu")(x)
        x = layers.Dropout(dropout_rate)(x)
    out = layers.Dense(1, activation="sigmoid")(x)

    model = keras.Model(inputs=inp, outputs=out)
    model.compile(optimizer="adam", loss="binary_crossentropy")
    # build & load weights
    _ = model.predict(np.zeros((1, num_fields), dtype=np.int32), verbose=0)
    try:
        model.load_weights(str(MODEL_W))
    except Exception as e:
        st.error("ê°€ì¤‘ì¹˜ ë¡œë“œ ì‹¤íŒ¨(model/autoInt_model.weights.h5). íŒŒì¼/êµ¬ì¡°ë¥¼ í™•ì¸í•˜ì„¸ìš”.\n\n" + str(e))
        st.stop()
    return cat_cols, label_encoders, field_dims, model

users, movies, ratings = load_small_tables()
cat_cols, label_encoders, field_dims, model = load_artifacts_and_model()

# -----------------------------
# 3) ìœ í‹¸
# -----------------------------
def map_single(col, val):
    m = label_encoders[col]
    return m.get(str(val), 0)

def recommend_for_user(original_user_id: int, topn: int = 10):
    """ìœ ì €ê°€ ë³´ì§€ ì•Šì€ ì˜í™”ì— ëŒ€í•´ ì ìˆ˜ ì˜ˆì¸¡ â†’ TopN"""
    urow = users[users["user_id"]==original_user_id]
    if len(urow)==0:
        g, a, o, z = "M", 25, 0, "00000"
    else:
        g, a, o, z = urow.iloc[0][["gender","age","occupation","zip"]]

    seen = set(ratings.loc[ratings["user_id"]==original_user_id, "movie_id"].tolist())
    cand = movies[~movies["movie_id"].isin(seen)].copy()
    if cand.empty:
        return pd.DataFrame(columns=["movie_id","title","genres","score"])

    cand["main_genre"] = cand["genres"].str.split("|").str[0]

    mg_idx = cand["main_genre"].astype(str).map(label_encoders["main_genre"]).fillna(0).astype(int).values
    m_idx  = cand["movie_id"].astype(str).map(label_encoders["movie_id"]).fillna(0).astype(int).values

    g_idx = map_single("gender", g)
    a_idx = map_single("age", a)
    o_idx = map_single("occupation", o)
    z_idx = map_single("zip", z)

    # ì…ë ¥ í–‰ë ¬ (í•™ìŠµ cat_cols ìˆœì„œì™€ ë™ì¼í•´ì•¼ í•¨)
    # ê¸°ë³¸: ["user_id","movie_id","gender","age","occupation","zip","main_genre"]
    n = len(cand)
    U = np.full((n,), map_single("user_id", original_user_id), dtype=np.int32)
    G = np.full((n,), g_idx, dtype=np.int32)
    A = np.full((n,), a_idx, dtype=np.int32)
    O = np.full((n,), o_idx, dtype=np.int32)
    Z = np.full((n,), z_idx, dtype=np.int32)
    X = np.stack([U, m_idx, G, A, O, Z, mg_idx], axis=1)

    scores = model.predict(X, batch_size=65536, verbose=0).ravel()
    cand = cand.assign(score=scores)
    top = cand.sort_values("score", ascending=False).head(topn)
    return top[["movie_id","title","genres","score"]]

def get_user_profile(uid: int, k: int = 10):
    hist = (
        ratings[ratings["user_id"]==uid]
        .sort_values("ts", ascending=False).head(k)
        .merge(movies[["movie_id","title","genres"]], on="movie_id", how="left")
    )
    return hist[["user_id","movie_id","rating","ts","title","genres"]]

# -----------------------------
# 4) UI
# -----------------------------
st.title("ğŸ¬ MovieLens AutoInt ì¶”ì²œ ê²°ê³¼")

col_a, col_b, col_c = st.columns([2,2,1])
with col_a:
    st.subheader("ì‚¬ìš©ì ì„ íƒ")
    uid = st.selectbox("User ID", options=sorted(users["user_id"].unique().tolist()), index=0)
with col_b:
    topn = st.slider("ì¶”ì²œ ê°œìˆ˜", 5, 50, 10, 1)
with col_c:
    st.write("")

st.divider()
st.markdown("#### ì‚¬ìš©ì ìµœê·¼ ì‹œì²­ ì´ë ¥")
st.dataframe(get_user_profile(uid, k=10), use_container_width=True, height=260)

if st.button("ğŸ” ì¶”ì²œ ê²°ê³¼ ë³´ê¸°", type="primary"):
    with st.spinner("ì¶”ì²œ ê³„ì‚° ì¤‘â€¦"):
        recs = recommend_for_user(int(uid), topn=topn)
    st.markdown("#### ì¶”ì²œ ê²°ê³¼")
    st.dataframe(recs.reset_index(drop=True), use_container_width=True, height=400)
else:
    st.info("ìƒë‹¨ì—ì„œ ì‚¬ìš©ì/ì¶”ì²œ ê°œìˆ˜ë¥¼ ì„¤ì •í•˜ê³  ë²„íŠ¼ì„ ëˆŒëŸ¬ ì£¼ì„¸ìš”.")
